<!DOCTYPE html>

<html>
<head>
  <title>vokram.py</title>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="dycco.css">
</head>
<body>
  <div id="container">
    <div id="background"></div>
    <table cellpadding="0" cellspacing="0">
      <thead>
        <tr>
          <th class="docs">
            <h1>vokram.py</h1>
          </th>
          <th class="code">
          </th>
        </tr>
      </thead>
      <tbody>
          <tr id="section-2">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-2">&#182;</a>
              </div>
              <p>A simple, generic implementation of Markov chains in Python, with some helpers
for generating chains of words. A brief overview of how this works:</p>
<ol>
<li>
<p>Build a Markov model from a given corpus, which can be a sequence of
    basically anything (e.g., numbers, words). Special support is provided for
    building models based on words in strings or file-like objects.</p>
<p>In this implementation, a model is a dictionary that maps tuples of
n-grams to lists of the items that appear after those n-grams in the input
corpus. The size of the n-grams is determined by the user, but currently
defaults to 2.</p>
<p>So, taking this simple corpus as an example (where <code>&gt;&gt;&gt;</code> represents the
interactive Python prompt):</p>
<pre><code>&gt;&gt;&gt; corpus = [1, 2, 3, 2, 4, 5, 6, 2, 1, 3]
</code></pre>
<p>The model, based on the default n-gram size of 2, would look like this:</p>
<pre><code>&gt;&gt;&gt; build_model(corpus)
{(1, 2): [3, 3, 4],
 (2, 1): [2],
 (2, 3): [1, 2],
 (2, 4): [3],
 (2, 5): [4],
 (3, 1): [2],
 (3, 2): [1, 5],
 (4, 3): [2, 1],
 (5, 4): [3]}
</code></pre>
<p>For reference, the model of the same corpus with an n-gram size of 3 would
look like this:</p>
<pre><code>&gt;&gt;&gt; build_model(corpus, n=3)
{(1, 2, 3): [1, 2],
 (1, 2, 4): [3],
 (2, 1, 2): [4],
 (2, 3, 1): [2],
 (2, 3, 2): [1],
 (2, 4, 3): [2],
 (2, 5, 4): [3],
 (3, 1, 2): [3],
 (3, 2, 1): [2],
 (3, 2, 5): [4],
 (4, 3, 2): [5],
 (5, 4, 3): [1]}
</code></pre>
</li>
<li>
<p>Once the model is built, we can use it to construct a Markov chain of (I
    think, though there's a decent chance I'm butchering some or all of these
    concepts) statistically likely outputs.</p>
<p>The process for building a chain works like this:</p>
<ol>
<li>
<p>Get a starting key in the model (chosen by the user or chosen
   randomly). For our purposes, let's choose the key <code>(2, 3)</code> from the
   first model above.</p>
</li>
<li>
<p>Pick a random item from the list that our chosen key points to and add
   it to our chain. Let's say we choose <code>2</code> from the list <code>[1, 2]</code>.</p>
</li>
<li>
<p>Build a new key by dropping the first item in our current key and
   appending the item we chose in step b. This gives us a new key,
   <code>(3, 2)</code>.</p>
</li>
<li>
<p>Start over at step b, using our new key. In this example, we'd end up
   choosing a random value from the list <code>[1, 5]</code> to add to our chain. Do
   this until the chain has reached the desired length.</p>
</li>
</ol>
</li>
</ol>
<p>Note, there is a specialized <code>markov_words</code> version of the <code>markov_chain</code>
function that tries to slightly better at generating Markov chains that make
complete-ish sentences by trying to pick good starting keys and ensuring that
the chain ends in some kind of "sentence-ending" punctuation.</p>
<p>With inspiration from <a href="http://code.activestate.com/recipes/194364-the-markov-chain-algorithm/">this Python implementation and explanation</a></p>
            </td>
            <td class="code">
              <div class="highlight"><pre>
</pre></div>

            </td>
          </tr>
          <tr id="section-81">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-81">&#182;</a>
              </div>
              
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>


<span class="n">DEFAULT_NGRAM_SIZE</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">MIN_SENTENCE_LENGTH</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-92">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-92">&#182;</a>
              </div>
              <h2>Basic interface</h2>
            </td>
            <td class="code">
              <div class="highlight"><pre>
</pre></div>

            </td>
          </tr>
          <tr id="section-93">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-93">&#182;</a>
              </div>
              <p>Generates a Markov chain with the given length based on the given
model. The chain will be returned as a list. If a starting key (in the
model) is not given, a random one will be chosen.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">def</span> <span class="nf">markov_chain</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">start_key</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">start_key</span> <span class="ow">or</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-103">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-103">&#182;</a>
              </div>
              <p>Add a random selection from the value corresponding to the current
 key to the chain.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>        <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
        <span class="n">chain</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-108">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-108">&#182;</a>
              </div>
              <p>Pick the next key by dropping the first item in the current key and
 appending the current item (manually creating the n-gram that will
 let us choose the next appropriate item for our chain)</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
    <span class="k">return</span> <span class="n">chain</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-112">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-112">&#182;</a>
              </div>
              <p>Builds a model of the given sequence using n-grams of size <code>n</code>. The
model is a dict mapping qn-gram keys to lists of items appearing
immediately after those n-grams.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">DEFAULT_NGRAM_SIZE</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">gen_ngrams</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">key</span><span class="p">,</span> <span class="n">item</span> <span class="o">=</span> <span class="n">ngram</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ngram</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">model</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-125">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-125">&#182;</a>
              </div>
              <h2>Word-based interface</h2>
            </td>
            <td class="code">
              <div class="highlight"><pre>
</pre></div>

            </td>
          </tr>
          <tr id="section-126">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-126">&#182;</a>
              </div>
              <p>Generates a Markov chain in the form of a sentence made up of
approximately the given number of words.</p>
<p>Attempts to be intelligent about generating chains made up of what
(hopefully) look like complete sentences, which means that the resulting
sentence will often have fewer than the desired number of words.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">def</span> <span class="nf">markov_words</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_words</span><span class="p">,</span> <span class="n">start_key</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-137">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-137">&#182;</a>
              </div>
              <p>An overly-simplistic heuristic to use to try to generate complete
 sentences</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="n">sentence_end</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;.&#39;</span><span class="p">,</span> <span class="s">&#39;!&#39;</span><span class="p">,</span> <span class="s">&#39;?&#39;</span><span class="p">,</span> <span class="s">&#39;&quot;&#39;</span><span class="p">,</span> <span class="s">&quot;&#39;&quot;</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-142">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-142">&#182;</a>
              </div>
              <p>Find a start key that (hopefully) indicates the end of a sentence, which
 will make it more likely that our chain will start with a word from the
 beginning of a sentence.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="k">if</span> <span class="n">start_key</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-148">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-148">&#182;</a>
              </div>
              <p>Making sure the key ends in a period (instead of anything in
 sentence_end) seems to yield better results at the start of the
 chain.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>        <span class="k">while</span> <span class="ow">not</span> <span class="n">key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s">&#39;.&#39;</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
        <span class="n">start_key</span> <span class="o">=</span> <span class="n">key</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-154">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-154">&#182;</a>
              </div>
              <p>Make sure our chain seems to end at the end of a sentence, by dropping
 any dangling words after the end of the last sentence in the chain.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="n">chain</span> <span class="o">=</span> <span class="n">markov_chain</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_words</span><span class="p">,</span> <span class="n">start_key</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">chain</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sentence_end</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">num_words</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">chain</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="n">sentence_end</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="n">chain</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-162">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-162">&#182;</a>
              </div>
              <p>Make sure we've got a reasonable-sized chain.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">MIN_SENTENCE_LENGTH</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">markov_words</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_words</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-168">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-168">&#182;</a>
              </div>
              <p>A special-case of build_model that knows how to build a model based on
words from a corpus given as a string or a file-like object.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">def</span> <span class="nf">build_word_model</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">DEFAULT_NGRAM_SIZE</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">build_model</span><span class="p">(</span><span class="n">gen_words</span><span class="p">(</span><span class="n">corpus</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-176">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-176">&#182;</a>
              </div>
              <h2>Utility functions</h2>
            </td>
            <td class="code">
              <div class="highlight"><pre>
</pre></div>

            </td>
          </tr>
          <tr id="section-177">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-177">&#182;</a>
              </div>
              <p>Yields n-grams from the given sequence. Assumes <code>len(xs) &gt;= n</code>. N-grams
are yielded as tuples of length <code>n</code>.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">def</span> <span class="nf">gen_ngrams</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">DEFAULT_NGRAM_SIZE</span><span class="p">):</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-182">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-182">&#182;</a>
              </div>
              <p>Explicitly capture an iterator over <code>xs</code>, because we'll need it twice</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="n">it</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-186">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-186">&#182;</a>
              </div>
              <p>Build and yield the first n-gram. This is where the assumption of
 <code>len(xs) &gt;= n</code> needs to be true.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="n">ngram</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">next</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">yield</span> <span class="n">ngram</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-191">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-191">&#182;</a>
              </div>
              <p>Each successive n-gram is built by dropping the first item of the
 previous n-gram and appending the current element</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">it</span><span class="p">:</span>
        <span class="n">ngram</span> <span class="o">=</span> <span class="n">ngram</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
        <span class="k">yield</span> <span class="n">ngram</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-196">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-196">&#182;</a>
              </div>
              <p>Yields each word from the given corpus, must be an iterator over lines
of strings.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">def</span> <span class="nf">gen_words</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">word</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-216">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-216">&#182;</a>
              </div>
              <h2>Command line interface</h2>
<p>This module can be run from the command line to generate sentences from a
 corpus of words provided on STDIN. It can be used like so:</p>
<pre><code> cat path/to/corpus.txt | ./vokram.py
</code></pre>
<p>or like so, if you want to specify your own maximum sentence length and
 n-gram size:</p>
<pre><code>cat path/to/corpus.txt | ./vokram.py --num-words=50 --ngram-size=4
</code></pre>
            </td>
            <td class="code">
              <div class="highlight"><pre><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">arg_parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
        <span class="n">prog</span><span class="o">=</span><span class="s">&#39;vokram&#39;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s">&#39;Generates plausible new sentences from a corpus provided &#39;</span>
                    <span class="s">&#39;on STDIN.&#39;</span><span class="p">)</span>
    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s">&#39;-w&#39;</span><span class="p">,</span> <span class="s">&#39;--num-words&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s">&#39;Maximum number of words in the resulting sentence.&#39;</span><span class="p">)</span>
    <span class="n">arg_parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s">&#39;-n&#39;</span><span class="p">,</span> <span class="s">&#39;--ngram-size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">DEFAULT_NGRAM_SIZE</span><span class="p">)</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">arg_parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
</pre></div>

            </td>
          </tr>
          <tr id="section-231">
            <td class="docs">
              <div class="pilwrap">
                <a class="pilcrow" href="#section-231">&#182;</a>
              </div>
              <p>One way to check whether anything has been piped into STDIN, though I'm
 not sure how reliable this is.</p>
            </td>
            <td class="code">
              <div class="highlight"><pre>    <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">isatty</span><span class="p">():</span>
        <span class="k">print</span> <span class="o">&gt;&gt;</span> <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span> <span class="s">&#39;Error: corpus must be provided on STDIN.&#39;</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">build_word_model</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ngram_size</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">print</span> <span class="n">markov_words</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_words</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;Error: Could not generate sentence with at least </span><span class="si">%d</span><span class="s"> words.&#39;</span> <span class="o">%</span>
               <span class="n">MIN_SENTENCE_LENGTH</span><span class="p">)</span>
        <span class="k">print</span> <span class="o">&gt;&gt;</span> <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span> <span class="n">msg</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

            </td>
          </tr>
      </tbody>
    </table>
    <footer>
      Generated by <b><a href="http://mccutchen.github.com/dycco/">Dycco</a></b>.
      Last updated <b>20 Nov 2013</b>.
    </footer>
  </div>
</body>
</html>
